# Exercise 4 - Infrastructure as Code

Infrastructure as Code (IaC) is the process of managing and provisioning computing infrastructure (e.g. servers, databases, networks, etc.) through machine-readable files, rather than physical hardware configuration or interactive configuration tools such as the AWS Management Console, Azure Portal, or Google Cloud Console.

The benefits of IaC include:

- **Consistency**: Infrastructure is defined in code and can be version-controlled, ensuring that the same configuration is used across all environments.
- **Reproducibility**: Infrastructure can be easily replicated across different environments, reducing the risk of configuration drift.
- **Scalability**: Infrastructure can be easily scaled up or down based on demand, without manual intervention.
- **Automation**: Infrastructure can be provisioned and managed automatically, reducing the need for manual intervention.

In this exercise, we will use [Terraform](https://developer.hashicorp.com/terraform/intro) and [Helm](https://circleci.com/blog/what-is-helm/) to define and provision infrastructure for our application running inside Minikube.

Terraform is an open-source IaC tool that enables users to define and provision infrastructure using a high-level configuration language.

Helm is a package manager for Kubernetes that allows users to define, install, and manage applications on Kubernetes.

Terraform and Helm can be used together to define and provision infrastructure for Kubernetes clusters, making it simpler to manage complex applications running on Kubernetes.

> ðŸ’¡ **Note:** Both tools can also be used separately, eg. if you don't need to manage Kubernetes resources you can skip using Helm and only use Terraform to provision and manage any kind of cloud resources on AWS, Azure, or Google Cloud.

## Pre-requisites

Make sure you have [Terraform](https://learn.hashicorp.com/tutorials/terraform/install-cli) and [Helm](https://helm.sh/docs/intro/install/) installed on your machine.

## 1. Initialise Terraform

To initialise Terraform, run the following command in the `/devops` directory:

```sh
terraform init
```

This will download the necessary providers and modules and initialise the Terraform state to keep track of the infrastructure changes.

> ðŸ’¡ **Note:** In a real world project the state file would be uploaded to a storage bucket to persist it.

## 2. Inspect the IaC configuration files

### Terraform Configuration

In the `/devops/infra` directory, you will find the main Terraform configuration file `main.tf` which is the entry point for defining the infrastructure.

It defines two providers: `helm` and `kubernetes` which are used to interact with the Kubernetes cluster in Minikube.

The provider configuration references the config file in `~/.kube/config` which is the default location for Kubernetes configuration.

We also specify that the context of the Kubernetes config is `minikube` which is the name of the Minikube cluster.

> ðŸ’¡ **Note:** This context should have been automatically written to your `~/.kube/config` file when you did the Minikube setup.

This file doesn't yet have any resources defined. Next we will inspect the Helm chart configuration and then see how we can reference it in the Terraform configuration to deploy it to the Kubernetes cluster.

### Helm configuration

In the `/devops/infra/helm` directory, you will find a Helm chart that defines the Kubernetes resources for the application. A Helm [chart](https://helm.sh/docs/topics/charts/) is a collection of files that describe a set of Kubernetes resources that can be deployed together as a single application.

The provided Helm chart defines resources and configurations for the web application (client + server) that we have been working on in the previous exercises. Both the client and the server have three resources defined under the `/helm/template` directory: a **Deployment**, a **Service**, and an **Ingress**.

- **Deployment** is a Kubernetes resource that defines a set of pods that run the application. The deployment ensures that the desired number of pods are running and automatically restarts failed pods.
- **Service** is a Kubernetes resource that defines a set of pods and provides a stable endpoint for accessing the application. The service can be used to expose the application to other services within the cluster or to external users.
- **Ingress** is a Kubernetes resource that defines rules for routing HTTP and HTTPS traffic to the application. The ingress can be used to expose the application to external users and to configure routing rules for different paths.

Helm automatically scans the `/helm/templates` directory and renders the templates to generate the Kubernetes resources when the chart is deployed.

The Helm chart also includes a `values.yaml` file that defines the configuration values for the application. The values file can be used to customize the application configuration, such as the number of replicas, the image tags, and the service ports.

The entry point for the Helm chart is the `Chart.yaml` file which defines the metadata for the chart, such as the name, version, and description.

Go through the different template parts and when you are ready continue to the next step.

## 3. Plan the infrastructure

Add the following code to the `main.tf` file to define a Helm release resource that will deploy the Helm chart to the Kubernetes cluster in Minikube:

```terraform
resource "helm_release" "app_release" {
  name      = "app-release"
  chart     = "./helm"
  namespace = "default"
  values = [
    "${file("./helm/values.yaml")}"
  ]
}
```

Next run the following command to plan the infrastructure changes:

```sh
terraform plan
```

This will show you the changes that Terraform will make to the infrastructure to deploy the Helm chart to the Kubernetes cluster. It is in general a good practice to always run `terraform plan` before applying any changes to the infrastructure to see what will be changed.

## 4. Prepare the Minikube cluster

Before we apply the infra changes we need to make sure we have the Minikube cluster running. If you don't have it running yet, start it by running:

```sh
minikube start
```

Also make sure you have the Ingrees controller running by running:

```sh
minikube addons enable ingress
```

Additionally you should have the client and server images built from the previous exercises. If you don't have them yet, build them by running:

```sh
docker build -t workshop-client:0.0.1 ./client
docker build -t workshop-server:0.0.1 ./server
```

Next we need to push the images to the Minikube Docker registry so that Terraform can pull them when deploying the Helm chart. To do that run:

```sh
minikube image load workshop-server:0.0.1
minikube image load workshop-client:0.0.1
```

> ðŸ’¡ **Note:** In real projects the CI would build the Docker images and push them to a registry like Docker Hub. This step is similar and emulates pushing the built images to a registry.

Finally before we apply the infra changes we can open the Minikube dashboard so we can see the resources being created. To do that run:

```sh
minikube dashboard
```

## 5. Apply the infrastructure changes

Now that we have the Minikube cluster running and the images loaded into the local Docker registry, we can apply the infrastructure changes by running:

```sh
terraform apply
```

This will display the changes that Terraform will make to the infrastructure and prompt you to confirm the changes. Type `yes` to apply the changes.

If everything goes well you should see the Helm chart being deployed to the Minikube cluster.

Before we can access the application we need to get the IP address of the Minikube cluster. To do that run:

```sh
minikube ip
```

Copy the IP address and add the following line to your `/etc/hosts` file:

```sh
<minikube-ip> taito-workshop.local
```

Now go to [taito-workshop.local](http://taito-workshop.local) in your browser to see the application running.

Vola ðŸŽ‰! You have successfully deployed the application to the Minikube cluster using Terraform and Helm ðŸ‘ðŸ»

## 6. Update the infrastructure

Let's make a small change to the application and see how we can update the infrastructure using Terraform.

Update the `server.js` file in the `/server` directory to return a different message:

```js
app.get("/data", (req, res) => {
  res.json({ message: "New message" });
});
```

Rebuild the server image and push it to the Minikube Docker registry:

```sh
docker build -t workshop-server:0.0.2 ./server
minikube image load workshop-server:0.0.2
```

Update the `values.yaml` file in the `/helm` directory to use the new image tag:

```yaml
server:
  image:
    repository: workshop-server
    tag: "0.0.2"
```

Run the following command to apply the changes to the infrastructure:

```sh
terraform apply -auto-approve
```

This will update the Helm release with the new image tag and deploy the updated application to the Kubernetes cluster.

Go to [taito-workshop.local](http://taito-workshop.local) in your browser to see the updated application running.

## 7. Clean up

To clean up the resources created by Terraform, run:

```sh
terraform destroy
```

This will remove all the resources created by Terraform, including the Helm release that was deployed to the Kubernetes cluster.

You can open the **Workloads** page in the Minikube dashboard to see that all the resources have been removed.

Finally you can delete the Minikube cluster by running:

```sh
minikube delete
```

## Next steps

In the next exercise we will see how all the pieces we have learned so far are used as building blocks of [Taito CLI](https://github.com/TaitoUnited/taito-cli).
